{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LEAFToolbox for Sites\n",
    "Applies the LEAF-ToolBox for mapping vegetation using satellite imagery over a list of sites, each defined using time stamped vector geographical objects.\n",
    "Cite as Fernandes, R. et al., 2021, \"LEAF Toolbox\", Canada Centre for Remote Sensing, https://github.com/rfernand387/LEAF-Toolbox/wiki, DOI: 10.5281/zenodo.4321298.\n",
    "\n",
    "\n",
    "LEAF currently supports two algorithms: \n",
    "SL2PV0 is the algorithm defined by Weiss and Baret (2016) with an update in Weiss and Baret (2020).  \n",
    "SL2PV1 defined in Fernandes et al. 2023 that attempts to correct for biases over forests observed in SL2PV1.\n",
    "\n",
    "\n",
    "Note: This is an exact copy of the Javascript version of the LEAF-ToolBox-SL2P for image by image products as implemented on December 1, 2023 17:21 EST: https://code.earthengine.google.com/8ee611fad1609740099eabbfe571189c. You will need a Google Earth Engine Account linked to a Google Account with sufficient disk space for the output.\n",
    "\n",
    "Refer to https://github.com/rfernand387/LEAF-Toolbox/tree/master/Source-Python for configuration of anaconda environment.\n",
    "\n",
    "\n",
    "Weiss, M. and Baret, F. 2016. S2ToolBox Level 2 products: LAI, FAPAR, FCOVER, 1.1. ed.\n",
    "Institut National de la Recherche Agronomique, Avignon, France. https://step.esa.\n",
    "int/docs/extra/ATBD_S2ToolBox_L2B_V1.1.pdf.\n",
    "\n",
    "Weiss, M., and Baret, F., 2020. S2ToolBox Level 2 Products: LAI, FAPAR, FCOVER, 2.0. ed.\n",
    "Institut National de la Recherche Agronomique, Avignon, France. https://step.esa.\n",
    "int/docs/extra/ATBD_S2ToolBox_L2B_V2.0.pdf.\n",
    "\n",
    "Fernandes et al., 2023. Evidence of a bias-variance tradeoff when mapping LAI over forests using Sentinel-2 imagery.  subitted to RSE>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=0j23fJ6HHZ2BBPoZqxAvM6k0Q38hqFaaI2WjQcuAu3Q&tc=BFEwkweKErV5ApiuP_-C6RgEVbJH0tjPh1Dlk1a8SGU&cc=9J8VlUgQPGyLH4cPnxahADhbZ0dyjbT4EgVkuy1G3xY>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=0j23fJ6HHZ2BBPoZqxAvM6k0Q38hqFaaI2WjQcuAu3Q&tc=BFEwkweKErV5ApiuP_-C6RgEVbJH0tjPh1Dlk1a8SGU&cc=9J8VlUgQPGyLH4cPnxahADhbZ0dyjbT4EgVkuy1G3xY</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AfJohXmQ5PFDJ2P1ORMT6F-4AifAL47Dz4SbJ5UOPPcctCix9ruXzbLUJic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "# Provide your GEE authentificaton\n",
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LEAF modules\n",
    "import LEAF\n",
    "\n",
    "# import algorith definitions\n",
    "import SL2PV0 \n",
    "import SL2PV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STARTING LEAF SITE\n",
      " \n",
      "Site:  projects/ee-modis250/assets/sampleAreas  with  2  features.\n",
      "Processing feature: 0\n",
      "Processing feature: 1\n",
      "\n",
      "DONE LEAF SITE\n",
      "\n",
      "Site:  projects/ee-modis250/assets/siteTwo  with  2  features.\n",
      "Processing feature: 0\n",
      "Processing feature: 1\n",
      "\n",
      "DONE LEAF SITE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "LEAF.sampleSites\n",
    "\n",
    "sitesDictionary = LEAF.sampleSites( siteList, \\\n",
    "                                    imageCollectionName=\"COPERNICUS/S2_SR_HARMONIZED\",\\\n",
    "                                    algorithm=SL2PV0, \\\n",
    "                                    variableName=\"LAI\",\\\n",
    "                                    maxCloudcover=90,\\\n",
    "                                    filterSize=0,\\\n",
    "                                    scaleSize=20,\\\n",
    "                                    bufferSize = 0,\\\n",
    "                                    deltaTime = [0,0])    \n",
    "                                    \n",
    "Applies a LEAF toolbox algorithm to map a canopy variable for all clear sky unmasked pixels from an input image collection\n",
    "falling within the spatial and temporal extents of features in a list of sites.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "siteList: list of readable GEE feature collection assets.  Features must have a system:time_start and system:time_end property.\n",
    "imageCollection: input image collection from one of the list defined by GEE\n",
    "                [\"COPERNICUS/S2_SR_HARMONIZED\",\"COPERNICUS/S2_SR_HARMONIZED_10m\",\"LANDSAT/LC08/C02/T1_L2\",\"LANDSAT/LC09/C02/T1_L2\",\"NASA/HLS/HLSL30/v002\"]\n",
    "algorith: python module specifying LEAF algorithm to apply , currently one of list [\"SL2PV0\",\"SL2PV1\"]\n",
    "variableName: variable to be mapped from one of the list [\"ALBEDO\",\"FAPAR\",\"FCOVER\",\"LAI\",\"CWC\",\"CCC\",\"DASF\"] defined by https://github.com/rfernand387/LEAF-Toolbox/wiki/Visualisation-Outputs              \n",
    "maxCloudCover: maximum input image cloud cover percentage [0,100]\n",
    "filterSize: width (m) of square filter applied to output\n",
    "scaleSize: width (m) of aggregation filter applied to input based on default for image collection selected\n",
    "bufferSize: width (m) of spatial buffer applied to features prior to sampling\n",
    "deltaTime: extension (d) of start and end time of sampled features\n",
    "\n",
    "Output:\n",
    "\n",
    "sitesDictionary: dictionary with keys corresponding to sites and structure.  The value of each key is a dictionary with two keys:\n",
    "                    'feature' : properties of the sampled feature\n",
    "                    'SL2PV0' or 'SL2PV1' : a pandas data frame where columns correspond to algorithm output properties and rows correspond to a retrieval within the time and spatial interval of the feature\n",
    "\n",
    "\n",
    "Example\"\n",
    "\n",
    "Apply SL2PV0 algorithm to Sentinel 2 imagery to map LAI over two sites.  \n",
    "The first Ottawa, Canada the second Karachi, Pakistan.\n",
    "\"\"\"\n",
    "\n",
    "sitesDictionaryL08 = LEAF.sampleSites(siteList=[\"projects/ee-modis250/assets/sampleAreas\",\"projects/ee-modis250/assets/siteTwo\"], \\\n",
    "                                                imageCollectionName='LANDSAT/LC08/C02/T1_L2',\\\n",
    "                                                algorithm=SL2PV0, \n",
    "                                                variableName=\"LAI\",\\\n",
    "                                                maxCloudcover=90,\\\n",
    "                                                filterSize=0,\\\n",
    "                                                scaleSize=30,\\\n",
    "                                                bufferSize = 0,\\\n",
    "                                                deltaTime = [0,0])                                      \n",
    "\n",
    "# List feature dictiomaries for each site's features\n",
    "# for site in sitesDictionaryL08.keys():\n",
    "#         print(\"\\nSite:\", site)\n",
    "#         for features in sitesDictionaryL08[site]:\n",
    "#             print('\\n Feature properties: \\n',features['feature'])\n",
    "#             print('\\n SL2PV0 LAI output: \\n',features['SL2PV0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STARTING LEAF SITE\n",
      " \n",
      "Site:  projects/ee-modis250/assets/sampleAreas  with  2  features.\n",
      "Processing feature: 0\n"
     ]
    },
    {
     "ename": "EEException",
     "evalue": "Image.bandNames: Parameter 'image' is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\leaf_prod\\Lib\\site-packages\\ee\\data.py:371\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\leaf_prod\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\leaf_prod\\Lib\\site-packages\\googleapiclient\\http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1/projects/earthengine-legacy/value:compute?prettyPrint=false&alt=json returned \"Image.bandNames: Parameter 'image' is required.\". Details: \"Image.bandNames: Parameter 'image' is required.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[666], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sitesDictionaryL09 \u001b[38;5;241m=\u001b[39m \u001b[43mLEAF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampleSites\u001b[49m\u001b[43m(\u001b[49m\u001b[43msiteList\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprojects/ee-modis250/assets/sampleAreas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprojects/ee-modis250/assets/siteTwo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mimageCollectionName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLANDSAT/LC09/C02/T1_L2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSL2PV0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mvariableName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLAI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mmaxCloudcover\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mfilterSize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mscaleSize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mbufferSize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mdeltaTime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m                                      \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# # List feature dictiomaries for each site's features\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# for site in sitesDictionaryL08.keys():\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#         print(\"\\nSite:\", site)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#         for features in sitesDictionaryL08[site]:\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#             print('\\n Feature properties: \\n',features['feature'])\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#             print('\\n SL2PV0 LAI output: \\n',features['SL2PV0'])\u001b[39;00m\n",
      "File \u001b[1;32m~\\Downloads\\LEAF-Toolbox-master\\LEAF-Toolbox-master\\Source-Python\\Source-With-Modules\\LEAF.py:163\u001b[0m, in \u001b[0;36msampleSites\u001b[1;34m(siteList, imageCollectionName, algorithm, variableName, maxCloudcover, filterSize, scaleSize, bufferSize, deltaTime)\u001b[0m\n\u001b[0;32m    160\u001b[0m     sampleFeature\u001b[38;5;241m=\u001b[39m getSamples(sampleRecords\u001b[38;5;241m.\u001b[39mget(n),variableName,collectionOptions[imageCollectionName],networkOptions[variableName][imageCollectionName],maxCloudcover,bufferSize,scaleSize,deltaTime,filterSize)\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sampleFeature :\n\u001b[0;32m    162\u001b[0m         result\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m: ee\u001b[38;5;241m.\u001b[39mDictionary(ee\u001b[38;5;241m.\u001b[39mFeature(sampleRecords\u001b[38;5;241m.\u001b[39mget(n))\u001b[38;5;241m.\u001b[39mtoDictionary())\u001b[38;5;241m.\u001b[39mgetInfo() , \\\n\u001b[1;32m--> 163\u001b[0m                        algorithm\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m : \u001b[43msamplestoDF\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampleFeature\u001b[49m\u001b[43m)\u001b[49m })\n\u001b[0;32m    165\u001b[0m outputDictionary\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;28minput\u001b[39m: result})\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDONE LEAF SITE\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Downloads\\LEAF-Toolbox-master\\LEAF-Toolbox-master\\Source-Python\\Source-With-Modules\\LEAF.py:134\u001b[0m, in \u001b[0;36msamplestoDF\u001b[1;34m(sampleFeature)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msamplestoDF\u001b[39m(sampleFeature):\n\u001b[0;32m    133\u001b[0m     sampleDF \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m--> 134\u001b[0m     sampleList \u001b[38;5;241m=\u001b[39m \u001b[43mee\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mee\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeature\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampleFeature\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoDictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# print(len(sampleList[0]))\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m sampleList:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\leaf_prod\\Lib\\site-packages\\ee\\computedobject.py:105\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Any]:\n\u001b[0;32m    100\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    The object can evaluate to anything.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputeValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\leaf_prod\\Lib\\site-packages\\ee\\data.py:1070\u001b[0m, in \u001b[0;36mcomputeValue\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   1067\u001b[0m body \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m: serializer\u001b[38;5;241m.\u001b[39mencode(obj, for_cloud_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[0;32m   1068\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[1;32m-> 1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprettyPrint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\leaf_prod\\Lib\\site-packages\\ee\\data.py:373\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mexecute(num_retries\u001b[38;5;241m=\u001b[39mnum_retries)\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 373\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[1;31mEEException\u001b[0m: Image.bandNames: Parameter 'image' is required."
     ]
    }
   ],
   "source": [
    "sitesDictionaryL09 = LEAF.sampleSites(siteList=[\"projects/ee-modis250/assets/sampleAreas\",\"projects/ee-modis250/assets/siteTwo\"], \\\n",
    "                                                imageCollectionName='LANDSAT/LC09/C02/T1_L2',\\\n",
    "                                                algorithm=SL2PV0, \n",
    "                                                variableName=\"LAI\",\\\n",
    "                                                maxCloudcover=90,\\\n",
    "                                                filterSize=0,\\\n",
    "                                                scaleSize=30,\\\n",
    "                                                bufferSize = 0,\\\n",
    "                                                deltaTime = [0,0])                                      \n",
    "\n",
    "# # List feature dictiomaries for each site's features\n",
    "# for site in sitesDictionaryL08.keys():\n",
    "#         print(\"\\nSite:\", site)\n",
    "#         for features in sitesDictionaryL08[site]:\n",
    "#             print('\\n Feature properties: \\n',features['feature'])\n",
    "#             print('\\n SL2PV0 LAI output: \\n',features['SL2PV0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitesDictionaryHLS = LEAF.sampleSites(siteList=[\"projects/ee-modis250/assets/sampleAreas\",\"projects/ee-modis250/assets/siteTwo\"], \\\n",
    "                                                imageCollectionName=\"NASA/HLS/HLSL30/v002\",\\\n",
    "                                                algorithm=SL2PV0, \n",
    "                                                variableName=\"LAI\",\\\n",
    "                                                maxCloudcover=90,\\\n",
    "                                                filterSize=0,\\\n",
    "                                                scaleSize=30,\\\n",
    "                                                bufferSize = 0,\\\n",
    "                                                deltaTime = [0,0])                                      \n",
    "\n",
    "# # List feature dictiomaries for each site's features\n",
    "# for site in sitesDictionaryHLS.keys():\n",
    "#         print(\"\\nSite:\", site)\n",
    "#         for features in sitesDictionary[site]:\n",
    "#             print('\\n Feature properties: \\n',features['feature'])\n",
    "#             print('\\n SL2PV0 LAI output: \\n',features['SL2PV0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitesDictionaryS2 = LEAF.sampleSites(siteList=[\"projects/ee-modis250/assets/sampleAreas\",\"projects/ee-modis250/assets/siteTwo\"], \\\n",
    "                                                imageCollectionName=\"COPERNICUS/S2_SR_HARMONIZED\",\\\n",
    "                                                algorithm=SL2PV0, \n",
    "                                                variableName=\"LAI\",\\\n",
    "                                                maxCloudcover=90,\\\n",
    "                                                filterSize=0,\\\n",
    "                                                scaleSize=20,\\\n",
    "                                                bufferSize = 0,\\\n",
    "                                                deltaTime = [0,0])                                      \n",
    "\n",
    "# # List feature dictiomaries for each site's features\n",
    "# for site in sitesDictionaryHLS.keys():\n",
    "#         print(\"\\nSite:\", site)\n",
    "#         for features in sitesDictionary[site]:\n",
    "#             print('\\n Feature properties: \\n',features['feature'])\n",
    "#             print('\\n SL2PV0 LAI output: \\n',features['SL2PV0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site=sitesDictionaryL08['projects/ee-modis250/assets/sampleAreas']\n",
    "df=site[0]['SL2PV0']\n",
    "df['utc'] =  pd.to_datetime(df['date'],unit='ms')\n",
    "pixelL08=df.loc[(df['longitude']==df.loc[0].longitude) & (df['latitude']==df.loc[0].latitude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site=sitesDictionaryHLS['projects/ee-modis250/assets/sampleAreas']\n",
    "df=site[0]['SL2PV0']\n",
    "df['utc'] =  pd.to_datetime(df['date'],unit='ms')\n",
    "pixelHLS=df.loc[(df['longitude']==df.loc[0].longitude) & (df['latitude']==df.loc[0].latitude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site=sitesDictionaryS2['projects/ee-modis250/assets/sampleAreas']\n",
    "df=site[0]['SL2PV0']\n",
    "df['utc'] =  pd.to_datetime(df['date'],unit='ms')\n",
    "pixelS2=df.loc[(df['longitude']==df.loc[0].longitude) & (df['latitude']==df.loc[0].latitude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site=sitesDictionaryL09['projects/ee-modis250/assets/sampleAreas']\n",
    "df=site[0]['SL2PV0']\n",
    "df['utc'] =  pd.to_datetime(df['date'],unit='ms')\n",
    "pixelL09=df.loc[(df['longitude']==df.loc[0].longitude) & (df['latitude']==df.loc[0].latitude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pixelL08['date'],pixelL08['estimateLAI'],'o')\n",
    "plt.plot(pixelS2['date'],pixelS2['estimateLAI'],'o')\n",
    "plt.plot(pixelHLS['date'],pixelHLS['estimateLAI'],'o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# performs same procedure as above block using SL2P10 network\n",
    "# reduces image resolution before applying algorithm\n",
    "    \n",
    "# filter collection and add ancillary bands\n",
    "if siteSelect == 'Ottawa':\n",
    "    input_collection_20m = ee.ImageCollection(COLLECTION_OPTIONS[colName][\"name\"]) \\\n",
    "                         .filterBounds(mapBounds) \\\n",
    "                         .filterDate('2020-08-01', '2020-08-05') \\\n",
    "                         .filterMetadata(colOptions[\"Cloudcover\"],'less_than',maxCloudcover) \\\n",
    "                         .limit(5000) \\\n",
    "                         .map(lambda image: ib.addDate(image)) \\\n",
    "                         .map(lambda image: image.clip(mapBounds)) \\\n",
    "                         .map(lambda image: ib.s2MaskClear(image)) \\\n",
    "                         .map(lambda image: ib.addS2Geometry(colOptions, image)) \\\n",
    "                         .map(lambda image: ib.reduceTo20m(image))\n",
    "\n",
    "else:\n",
    "    input_collection_20m = ee.ImageCollection(testImage) \\\n",
    "                         .map(lambda image: ib.addDate(image)) \\\n",
    "                         .map(lambda image: image.clip(mapBounds)) \\\n",
    "                         .map(lambda image: ib.s2MaskClear(image)) \\\n",
    "                         .map(lambda image: ib.s2MaskLand(image)) \\\n",
    "                         .map(lambda image: ib.addS2Geometry(colOptions, image)) \\\n",
    "                         .map(lambda image: ib.reduceTo20m(image))\n",
    "\n",
    "\n",
    "if outputName == \"Surface_Reflectance\":\n",
    "    export_collection_20m = input_collection_20m\n",
    "else:\n",
    "    # get partition used to select network\n",
    "    partition = (COLLECTION_OPTIONS[colName][\"partition\"]).filterBounds(mapBounds).mosaic().clip(mapBounds).rename('partition')\n",
    "\n",
    "    # pre process input imagery and flag invalid inputs\n",
    "    scaled_input_collection_20m = input_collection_20m.map(lambda image: ib.s2MaskLand(image)) \\\n",
    "                                                      .map(lambda image: ib.scaleBands(netOptions[\"inputBands\"],netOptions[\"inputScaling\"],image)) \\\n",
    "                                                      .map(lambda image: ib.invalidInput(COLLECTION_OPTIONS[colName][\"sl2pDomain\"],netOptions[\"inputBands\"],image))\n",
    "    \n",
    "    # apply networks to produce mapped parameters\n",
    "    estimateSL2P_20m = scaled_input_collection_20m.map(lambda image: wn.wrapperNNets(SL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"estimate\", image, outputName))\n",
    "    uncertaintySL2P_20m = scaled_input_collection_20m.map(lambda image: wn.wrapperNNets(errorsSL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"error\", image, outputName))\n",
    "\n",
    "    # scale and offset mapped parameter bands\n",
    "    estimateSL2P_20m = estimateSL2P_20m.map(lambda image: image.addBands(image.select(\"estimate\"+outputName) \\\n",
    "                                                               .multiply(ee.Image.constant(outputScale)) \\\n",
    "                                                               .add(ee.Image.constant(outputOffset)), overwrite = True))\n",
    "    uncertaintySL2P_20m = uncertaintySL2P_20m.map(lambda image: image.addBands(image.select(\"error\"+outputName) \\\n",
    "                                                                     .multiply(ee.Image.constant(outputScale)) \\\n",
    "                                                                     .add(ee.Image.constant(outputOffset)),overwrite = True))\n",
    "    \n",
    "    # produce final export collection\n",
    "    export_collection_20m = input_collection_20m.combine(estimateSL2P_20m).combine(uncertaintySL2P_20m)\n",
    "\n",
    "image_output_names_20m = ([name+\"_\"+outputName+\"_20m\" for name in export_collection_20m.toList(export_collection_20m.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "ee_func.displayImage(export_collection_20m.mosaic().select('estimate'+outputName),0+outputOffset,10*outputScale+outputOffset, mapBounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# performs same procedure as above block using SL2P10 network\n",
    "# applies algorithm to 10 m bands ; generates a 10 m map\n",
    "\n",
    "# filter collection and add ancillary bands\n",
    "if siteSelect == 'Ottawa':\n",
    "    input_collection_10m = ee.ImageCollection(COLLECTION_OPTIONS[colName][\"name\"]) \\\n",
    "                         .filterBounds(mapBounds) \\\n",
    "                         .filterDate('2020-08-01', '2020-08-05') \\\n",
    "                         .filterMetadata(colOptions[\"Cloudcover\"],'less_than',maxCloudcover) \\\n",
    "                         .limit(5000) \\\n",
    "                         .map(lambda image: ib.addDate(image)) \\\n",
    "                         .map(lambda image: image.clip(mapBounds)) \\\n",
    "                         .map(lambda image: ib.s2MaskClear(image)) \\\n",
    "                         .map(lambda image: ib.addS2Geometry(colOptions, image))\n",
    "\n",
    "else:\n",
    "    input_collection_10m = ee.ImageCollection(testImage) \\\n",
    "                         .map(lambda image: ib.addDate(image)) \\\n",
    "                         .map(lambda image: image.clip(mapBounds)) \\\n",
    "                         .map(lambda image: ib.s2MaskClear(image)) \\\n",
    "                         .map(lambda image: ib.s2MaskLand(image)) \\\n",
    "                         .map(lambda image: ib.addS2Geometry(colOptions, image))\n",
    "\n",
    "if outputName == \"Surface_Reflectance\":\n",
    "    export_collection_10m = input_collection_10m\n",
    "else:\n",
    "    # get partition used to select network\n",
    "    partition = (COLLECTION_OPTIONS[colName][\"partition\"]).filterBounds(mapBounds).mosaic().clip(mapBounds).rename('partition')\n",
    "    \n",
    "    # pre process input imagery and flag invalid inputs\n",
    "    scaled_input_collection_10m = input_collection_10m.map(lambda image: ib.s2MaskLand(image)) \\\n",
    "                                                      .map(lambda image: ib.scaleBands(netOptions[\"inputBands\"],netOptions[\"inputScaling\"],image)) \\\n",
    "                                                      .map(lambda image: ib.invalidInput(COLLECTION_OPTIONS[colName][\"sl2pDomain\"],netOptions[\"inputBands\"],image))\n",
    "    \n",
    "    # apply networks to produce mapped parameters\n",
    "    estimateSL2P_10m = scaled_input_collection_10m.map(lambda image: wn.wrapperNNets(SL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"estimate\", image, outputName))\n",
    "    uncertaintySL2P_10m = scaled_input_collection_10m.map(lambda image: wn.wrapperNNets(errorsSL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"error\", image, outputName))\n",
    "    \n",
    "    # scale and offset mapped parameter bands\n",
    "    estimateSL2P_10m = estimateSL2P_10m.map(lambda image: image.addBands(image.select(\"estimate\"+outputName) \\\n",
    "                                                                 .multiply(ee.Image.constant(outputScale)) \\\n",
    "                                                                 .add(ee.Image.constant(outputOffset)), overwrite = True));\n",
    "    uncertaintySL2P_10m = uncertaintySL2P_10m.map(lambda image: image.addBands(image.select(\"error\"+outputName) \\\n",
    "                                                                       .multiply(ee.Image.constant(outputScale)) \\\n",
    "                                                                       .add(ee.Image.constant(outputOffset)),overwrite = True));\n",
    "    \n",
    "    \n",
    "    # produce final export collection\n",
    "    export_collection_10m = input_collection_10m.combine(estimateSL2P_10m).combine(uncertaintySL2P_10m)\n",
    "\n",
    "image_output_names_10m = ([name+\"_\"+outputName+\"_10m\" for name in export_collection_10m.toList(export_collection_10m.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "ee_func.displayImage(export_collection_10m.mosaic().select('estimate'+outputName),0+outputOffset,10*outputScale+outputOffset, mapBounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine all SL2P, SL2P10_10m, SL2P10_20m bands into a single image to sample corresponding pixel values\n",
    "\n",
    "export_20m = export_collection_20m.first()\n",
    "export_10m = export_collection_10m.first()\n",
    "\n",
    "export_20m = export_20m.select('estimate'+outputName).rename('estimate'+outputName+'_20m')\n",
    "export_10m = export_10m.select('estimate'+outputName).rename('estimate'+outputName+'_10m')\n",
    "\n",
    "# get the first image in export_collection ; add all bands from corresponding image in export_collection_10m and export_collection_10m\n",
    "full_image = export_collection.first().addBands(export_20m).addBands(export_10m)\n",
    "\n",
    "# sample the composed image with SL2P10_10m and SL2P10_20m bands\n",
    "samples = full_image.select('estimate'+outputName, 'estimate'+outputName+'_20m', 'estimate'+outputName+'_10m').sample(numPixels=5000, projection=export_collection.first().select('estimate'+outputName)\\\n",
    "                                                             .projection(), scale=10).getInfo()\n",
    "\n",
    "list_length = len(samples['features'])\n",
    "estimate_list = []\n",
    "\n",
    "# populate an array with the estimate for SL2P, SL2P10_10m, SL2P10_20m\n",
    "for i in range(list_length):\n",
    "    temp_list = []\n",
    "    temp_list.append(samples['features'][i]['properties']['estimate'+outputName])\n",
    "    temp_list.append(samples['features'][i]['properties']['estimate'+outputName+'_20m'])\n",
    "    temp_list.append(samples['features'][i]['properties']['estimate'+outputName+'_10m'])\n",
    "    estimate_list.append(temp_list)\n",
    "\n",
    "estimate_array = pd.DataFrame(estimate_list).rename(columns={0:'estimate'+outputName, 1:'estimate'+outputName+'_20m', 2:'estimate'+outputName+'_10m'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sl2p = estimate_array['estimate'+outputName]/outputScale\n",
    "sl2p10_10m = estimate_array['estimate'+outputName+'_10m']/outputScale\n",
    "sl2p10_20m = estimate_array['estimate'+outputName+'_20m']/outputScale\n",
    "\n",
    "xy_10m = np.vstack([sl2p, sl2p10_10m])\n",
    "xy_20m = np.vstack([sl2p, sl2p10_20m])\n",
    "\n",
    "density_10m = scipy.stats.gaussian_kde(xy_10m)(xy_10m)\n",
    "density_20m = scipy.stats.gaussian_kde(xy_20m)(xy_20m)\n",
    "\n",
    "rmse_10m = sklearn.metrics.mean_squared_error(sl2p, sl2p10_10m, squared=False)\n",
    "rmse_20m = sklearn.metrics.mean_squared_error(sl2p, sl2p10_20m, squared=False)\n",
    "\n",
    "\n",
    "# plot density histogram of SL2P estimate vs. (a) SL2P10_20m and (b) SL2P10_10m\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,7))\n",
    "x = np.linspace(0,outputMax)\n",
    "fig.suptitle('{}'.format('Estimated '+outputName))\n",
    "\n",
    "# SL2P vs. SL2P10_20m\n",
    "fig1 = ax[0].scatter(sl2p, sl2p10_20m, c=density_20m)\n",
    "ax[0].set_xlabel('SL2P')\n",
    "ax[0].set_ylabel('SL2P10_20m')\n",
    "ax[0].plot(x, x, c='r')\n",
    "ax[0].title.set_text(f'RMSE={rmse_20m:.5f}')\n",
    "#plt.colorbar(mappable=fig1, ax=ax[0])\n",
    "\n",
    "# SL2P vs. SL2P10_10m\n",
    "fig2 = ax[1].scatter(sl2p, sl2p10_10m, c=density_10m)\n",
    "ax[1].set_xlabel('SL2P')\n",
    "ax[1].set_ylabel('SL2P10_10m')\n",
    "ax[1].plot(x, x, c='r')\n",
    "ax[1].title.set_text(f'RMSE={rmse_10m:.5f}')\n",
    "#plt.colorbar(mappable=fig2, ax=ax[1])\n",
    "\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cbar_ax = fig.add_axes([0.95, 0.1, 0.01, 0.8])\n",
    "fig.colorbar(fig1, cax=cbar_ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
